1. Documentation: MobileNetV2-7 (ONNX)

This model is the "Brain" of your current application.
Feature	Specification
Model Architecture	MobileNetV2 (Sandler et al., Google, 2018)
Format	ONNX (Open Neural Network Exchange)
Opset Version	7 (This refers to the ONNX file format version, not the model version)
File Size	Approx. 14 MB
Parameter Count	~3.4 Million (Very small compared to ResNet-50's 25 million)
The Dataset: ImageNet (ILSVRC 2012)

The model was trained on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 dataset.

    Training Images: ~1.28 million images.

    Validation Images: 50,000 images.

    Classes: 1,000 distinct categories.

        Examples: "Goldfish" (Index 1), "Great White Shark" (Index 2), "Golden Retriever" (Index 207), "Airliner" (Index 404), "Toilet Tissue" (Index 999).

    Goal: The model learned to look at an image and predict probability scores for these 1,000 specific categories.

Input Requirements (The "Contract")

To get a valid prediction, your input tensor must strictly match these dimensions and preprocessing rules:

    Shape: (1, 3, 224, 224) â†’ (Batch_Size, Channels, Height, Width).

    Color Space: RGB (Red, Green, Blue).

    Normalization:

        Range: 0.0 to 1.0 (Pixel value / 255.0).

        Mean: [0.485, 0.456, 0.406] (Subtract these values).

        Std: [0.229, 0.224, 0.225] (Divide by these values).

